{
  "name": "Open WebUI",
  "logo": "QmVDEiXJcSXvSWsx5DhRvMoufg3j2H7jK1Yv8ijAZfBEtv",
  "tags": [
    "ai",
    "self-hosted",
    "homelab",
    "docker",
    "open-source",
    "utility",
    "llm",
    "chatbot"
  ],
  "ports": [
    { "port": 8080, "protocol": "HTTP", "label": "Web UI" }
  ],
  "short_description": "User-friendly ChatGPT-style interface for running local LLMs with Ollama.",
  "description": "Open WebUI is a powerful, extensible ChatGPT-like user interface designed specifically for running local Large Language Models through Ollama. It provides an intuitive chat experience with support for various LLM models, conversation history, prompt templates, code syntax highlighting, image generation integration, and more. Features include full-text search through conversations, admin panel for user management, RAG (Retrieval-Augmented Generation) with document upload, web search integration, custom prompts, and a pipeline system for extending functionality. It's the most popular self-hosted AI chat interface.",
  "usecases": [
    "Chat with local LLMs (Llama, Mistral, Codellama) completely offline for privacy.",
    "Build a private AI assistant for work or personal use without sending data to OpenAI.",
    "Upload documents and ask questions about them using RAG functionality.",
    "Integrate with image generation models for a complete AI experience."
  ],
  "website": "https://github.com/open-webui/open-webui",
  "dependencies": ["ollama"],
  "notes": [
    "Requires Ollama to be running with models downloaded",
    "Connects to Ollama on internal Docker network",
    "Supports multiple users with admin controls"
  ]
}
