{
  "name": "Open WebUI",
  "logo": "QmVDEiXJcSXvSWsx5DhRvMoufg3j2H7jK1Yv8ijAZfBEtv",
  "tags": [
    "ai",
    "self-hosted",
    "homelab",
    "docker",
    "open-source",
    "utility"
  ],
  "short_description": "Web UI for chatting with local LLMs via Ollama. Self-host it with Docker using Yantr.",
  "description": "Web UI for chatting with local LLMs via Ollama. Self-host it with Docker using Yantr. Open WebUI is a self-hosted application focused on ai, self-hosted, homelab, docker. It can be deployed on any device via Docker Compose.",
  "usecases": [
    "Self-host Open WebUI on your home server to web ui for chatting with local llms via ollama. self-host it with docker using yantr without depending on third-party cloud services.",
    "Use Open WebUI to manage your ai workflows privately, keeping all data under your control on local infrastructure."
  ],
  "website": "https://github.com/open-webui/open-webui",
  "dependencies": [
    "ollama"
  ],
  "ports": [
    {
      "port": 8080,
      "protocol": "HTTP",
      "label": "Web UI"
    }
  ]
}
